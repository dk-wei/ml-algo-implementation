{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Imbalanced_Learning_Method_Comparision.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dk-wei/ml-algo-implementation/blob/main/Imbalanced_Learning_Method_Comparision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUZEjBgFmaxC"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAh9Zp8xmaxH"
      },
      "source": [
        "\n",
        "# Fitting model on imbalanced datasets and how to fight bias\n",
        "\n",
        "This example illustrates the problem induced by learning on datasets having\n",
        "imbalanced classes. Subsequently, we compare different approaches alleviating\n",
        "these negative effects.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1A3EryLmaxI"
      },
      "source": [
        "# Authors: Guillaume Lemaitre <g.lemaitre58@gmail.com>\n",
        "# License: MIT"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZsT7k5Am5c6",
        "outputId": "a829db44-3e10-4b11-9e88-1fadb7ebaa50"
      },
      "source": [
        "pip install -U imbalanced-learn"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (0.24.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZXE8DcMmaxI",
        "outputId": "f9f88cc6-7f3e-4aa1-ad12-ebbb2185a2a0"
      },
      "source": [
        "print(__doc__)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXS0HLzBmaxI"
      },
      "source": [
        "## Problem definition\n",
        "\n",
        "We are dropping the following features:\n",
        "\n",
        "- \"fnlwgt\": this feature was created while studying the \"adult\" dataset.\n",
        "  Thus, we will not use this feature which is not acquired during the survey.\n",
        "- \"education-num\": it is encoding the same information than \"education\".\n",
        "  Thus, we are removing one of these 2 features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW_yEF4fmaxJ"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "df, y = fetch_openml(\"adult\", version=2, as_frame=True, return_X_y=True)\n",
        "df = df.drop(columns=[\"fnlwgt\", \"education-num\"])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "Jf0aN4_VoSkZ",
        "outputId": "7fef417c-868e-4a40-d0da-ec5c77a428a4"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>11th</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Farming-fishing</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28.0</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Protective-serv</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>7688.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  workclass     education  ... capital-loss hours-per-week native-country\n",
              "0  25.0    Private          11th  ...          0.0           40.0  United-States\n",
              "1  38.0    Private       HS-grad  ...          0.0           50.0  United-States\n",
              "2  28.0  Local-gov    Assoc-acdm  ...          0.0           40.0  United-States\n",
              "3  44.0    Private  Some-college  ...          0.0           40.0  United-States\n",
              "4  18.0        NaN  Some-college  ...          0.0           30.0  United-States\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-uEs0T2maxJ"
      },
      "source": [
        "The \"adult\" dataset as a class ratio of about 3:1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6cJllJ2maxJ",
        "outputId": "730c0be0-949b-4e58-e044-d975216e7ccc"
      },
      "source": [
        "classes_count = y.value_counts()\n",
        "classes_count"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<=50K    37155\n",
              ">50K     11687\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Osh_H1AHmaxJ"
      },
      "source": [
        "This dataset is only slightly imbalanced. To better highlight the effect of\n",
        "learning from an imbalanced dataset, we will increase its ratio to 30:1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzRIwA8amaxK",
        "outputId": "e2390ca8-fe15-4a2d-9acd-298ab428ec4f"
      },
      "source": [
        "# make_imbalance可以创造imbalanced dataset\n",
        "from imblearn.datasets import make_imbalance\n",
        "\n",
        "ratio = 30\n",
        "df_res, y_res = make_imbalance(\n",
        "    df,\n",
        "    y,\n",
        "    sampling_strategy={classes_count.idxmin(): classes_count.max() // ratio},\n",
        ")\n",
        "y_res.value_counts()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<=50K    37155\n",
              ">50K      1238\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaVaVI8wmaxK"
      },
      "source": [
        "We will perform a cross-validation evaluation to get an estimate of the test\n",
        "score.\n",
        "\n",
        "As a baseline, we could use a classifier which will **always predict the\n",
        "majority class independently of the features provided**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys8_efJAmaxK",
        "outputId": "2133f4a4-d6b2-4a52-a425-fee9f55f0085"
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "scoring = [\"accuracy\", \"balanced_accuracy\"]\n",
        "cv_result = cross_validate(dummy_clf, df_res, y_res, scoring=scoring)\n",
        "print(f\"Accuracy score of a dummy classifier: {cv_result['test_accuracy'].mean():.3f}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score of a dummy classifier: 0.968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EDizZvYmaxK"
      },
      "source": [
        "Instead of using the accuracy, we can use the balanced accuracy which will\n",
        "take into account the balancing issue.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MNNjZ4dpeak",
        "outputId": "ecdcc5c3-d489-4779-8739-16ec6bcf0f96"
      },
      "source": [
        "cv_result"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.01961875, 0.09264684, 0.01842165, 0.01979184, 0.01916909]),\n",
              " 'score_time': array([0.04253268, 0.04647183, 0.04811263, 0.04082274, 0.04024887]),\n",
              " 'test_accuracy': array([0.96770413, 0.96770413, 0.96770413, 0.96783016, 0.96783016]),\n",
              " 'test_balanced_accuracy': array([0.5, 0.5, 0.5, 0.5, 0.5])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCGS97QPmaxL",
        "outputId": "998f9327-d874-42a7-bb0a-25e1f67914a6"
      },
      "source": [
        "print(\n",
        "    f\"Balanced accuracy score of a dummy classifier: \"\n",
        "    f\"{cv_result['test_balanced_accuracy'].mean():.3f}\"\n",
        ")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Balanced accuracy score of a dummy classifier: 0.500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeriSVBmmaxL"
      },
      "source": [
        "## Strategies to learn from an imbalanced dataset\n",
        "We will use a dictionary and a list to continuously store the results of\n",
        "our experiments and show them as a pandas dataframe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzcrC2GumaxL"
      },
      "source": [
        "index = []\n",
        "scores = {\"Accuracy\": [], \"Balanced accuracy\": []}"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw0b-GPhmaxL"
      },
      "source": [
        "### Dummy baseline\n",
        "\n",
        "Before to train a real machine learning model, we can store the results\n",
        "obtained with our :class:`~sklearn.dummy.DummyClassifier`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "VAn0tOD4maxL",
        "outputId": "38a5e5d4-422c-421b-c100-50f82ba46776"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "index += [\"Dummy classifier\"]\n",
        "cv_result = cross_validate(dummy_clf, df_res, y_res, scoring=scoring)\n",
        "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
        "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
        "\n",
        "df_scores = pd.DataFrame(scores, index=index)\n",
        "df_scores"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Dummy classifier</th>\n",
              "      <td>0.967755</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Accuracy  Balanced accuracy\n",
              "Dummy classifier  0.967755                0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LgkZkzamaxM"
      },
      "source": [
        "### Linear classifier baseline\n",
        "\n",
        "We will create a machine learning pipeline using a\n",
        ":class:`~sklearn.linear_model.LogisticRegression` classifier. In this regard,\n",
        "we will need to one-hot encode the categorical columns and standardized the\n",
        "numerical columns before to inject the data into the\n",
        ":class:`~sklearn.linear_model.LogisticRegression` classifier.\n",
        "\n",
        "First, we define our numerical and categorical pipelines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k31ypPuBmaxM"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "num_pipe = make_pipeline(\n",
        "    StandardScaler(), SimpleImputer(strategy=\"mean\", add_indicator=True)\n",
        ")\n",
        "cat_pipe = make_pipeline(\n",
        "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
        "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
        ")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSU0ZmEUmaxM"
      },
      "source": [
        "Then, we can create a preprocessor which will dispatch the categorical\n",
        "columns to the categorical pipeline and the numerical columns to the\n",
        "numerical pipeline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUjBvyrMmaxM"
      },
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.compose import make_column_selector as selector\n",
        "\n",
        "preprocessor_linear = make_column_transformer(\n",
        "    (num_pipe, selector(dtype_include=\"number\")),\n",
        "    (cat_pipe, selector(dtype_include=\"category\")),\n",
        "    n_jobs=2,\n",
        ")"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0vz5fskmaxM"
      },
      "source": [
        "Finally, we connect our preprocessor with our\n",
        ":class:`~sklearn.linear_model.LogisticRegression`. We can then evaluate our\n",
        "model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTey4YOsmaxM"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf = make_pipeline(preprocessor_linear, LogisticRegression(max_iter=1000))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "JuRI1PnRmaxN",
        "outputId": "91923e29-c8aa-4fa0-e20b-e5f341b390a6"
      },
      "source": [
        "index += [\"Logistic regression\"]\n",
        "cv_result = cross_validate(lr_clf, df_res, y_res, scoring=scoring)\n",
        "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
        "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
        "\n",
        "df_scores = pd.DataFrame(scores, index=index)\n",
        "df_scores"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Dummy classifier</th>\n",
              "      <td>0.967755</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic regression</th>\n",
              "      <td>0.970724</td>\n",
              "      <td>0.56946</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Accuracy  Balanced accuracy\n",
              "Dummy classifier     0.967755            0.50000\n",
              "Logistic regression  0.970724            0.56946"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6Yb99R2maxN"
      },
      "source": [
        "We can see that our linear model is learning slightly better than our dummy\n",
        "baseline. However, it is impacted by the class imbalance.\n",
        "\n",
        "We can verify that something similar is happening with a tree-based model\n",
        "such as :class:`~sklearn.ensemble.RandomForestClassifier`. With this type of\n",
        "classifier, we will not need to scale the numerical data, and we will only\n",
        "need to ordinal encode the categorical data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kPwd-U6maxN"
      },
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "num_pipe = SimpleImputer(strategy=\"mean\", add_indicator=True)\n",
        "cat_pipe = make_pipeline(\n",
        "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
        "    OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
        ")\n",
        "\n",
        "preprocessor_tree = make_column_transformer(\n",
        "    (num_pipe, selector(dtype_include=\"number\")),\n",
        "    (cat_pipe, selector(dtype_include=\"category\")),\n",
        "    n_jobs=2,\n",
        ")\n",
        "\n",
        "rf_clf = make_pipeline(\n",
        "    preprocessor_tree, RandomForestClassifier(random_state=42, n_jobs=2)\n",
        ")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "tAvR7mMEmaxN",
        "outputId": "64bc8a6c-e84f-4cf4-e754-bdc352c3214f"
      },
      "source": [
        "index += [\"Random forest\"]\n",
        "cv_result = cross_validate(rf_clf, df_res, y_res, scoring=scoring)\n",
        "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
        "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
        "\n",
        "df_scores = pd.DataFrame(scores, index=index)\n",
        "df_scores"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Dummy classifier</th>\n",
              "      <td>0.967755</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic regression</th>\n",
              "      <td>0.970724</td>\n",
              "      <td>0.569460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest</th>\n",
              "      <td>0.971505</td>\n",
              "      <td>0.629606</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Accuracy  Balanced accuracy\n",
              "Dummy classifier     0.967755           0.500000\n",
              "Logistic regression  0.970724           0.569460\n",
              "Random forest        0.971505           0.629606"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQFiJW3YmaxO"
      },
      "source": [
        "The :class:`~sklearn.ensemble.RandomForestClassifier` is as well affected by\n",
        "the class imbalanced, slightly less than the linear model. Now, we will\n",
        "present different approach to improve the performance of these 2 models.\n",
        "\n",
        "### Use `class_weight`\n",
        "\n",
        "Most of the models in `scikit-learn` have a parameter `class_weight`. **This\n",
        "parameter will affect the computation of the loss in linear model or the\n",
        "criterion in the tree-based model to penalize differently a false\n",
        "classification from the minority and majority class**. We can set\n",
        "`class_weight=\"balanced\"` such that the weight applied is inversely\n",
        "proportional to the class frequency. We test this parametrization in both\n",
        "linear model and tree-based model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "QK5sc812maxO",
        "outputId": "ec10d0c1-7b39-4a9b-e769-ea8aa4687be1"
      },
      "source": [
        "lr_clf.set_params(logisticregression__class_weight=\"balanced\")\n",
        "\n",
        "index += [\"Logistic regression with balanced class weights\"]\n",
        "cv_result = cross_validate(lr_clf, df_res, y_res, scoring=scoring)\n",
        "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
        "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
        "\n",
        "df_scores = pd.DataFrame(scores, index=index)\n",
        "df_scores"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Dummy classifier</th>\n",
              "      <td>0.967755</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic regression</th>\n",
              "      <td>0.970724</td>\n",
              "      <td>0.569460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest</th>\n",
              "      <td>0.971505</td>\n",
              "      <td>0.629606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic regression with balanced class weights</th>\n",
              "      <td>0.797724</td>\n",
              "      <td>0.814664</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Accuracy  Balanced accuracy\n",
              "Dummy classifier                                 0.967755           0.500000\n",
              "Logistic regression                              0.970724           0.569460\n",
              "Random forest                                    0.971505           0.629606\n",
              "Logistic regression with balanced class weights  0.797724           0.814664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "A4jfurmQmaxO",
        "outputId": "6d723165-9aa7-4ff3-f8ba-781dcf02f81c"
      },
      "source": [
        "rf_clf.set_params(randomforestclassifier__class_weight=\"balanced\")\n",
        "\n",
        "index += [\"Random forest with balanced class weights\"]\n",
        "cv_result = cross_validate(rf_clf, df_res, y_res, scoring=scoring)\n",
        "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
        "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
        "\n",
        "df_scores = pd.DataFrame(scores, index=index)\n",
        "df_scores"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Dummy classifier</th>\n",
              "      <td>0.967755</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic regression</th>\n",
              "      <td>0.970724</td>\n",
              "      <td>0.569460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest</th>\n",
              "      <td>0.971505</td>\n",
              "      <td>0.629606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic regression with balanced class weights</th>\n",
              "      <td>0.797724</td>\n",
              "      <td>0.814664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest with balanced class weights</th>\n",
              "      <td>0.963196</td>\n",
              "      <td>0.624159</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Accuracy  Balanced accuracy\n",
              "Dummy classifier                                 0.967755           0.500000\n",
              "Logistic regression                              0.970724           0.569460\n",
              "Random forest                                    0.971505           0.629606\n",
              "Logistic regression with balanced class weights  0.797724           0.814664\n",
              "Random forest with balanced class weights        0.963196           0.624159"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhFqwfDNmaxP"
      },
      "source": [
        "We can see that **using `class_weight` was really effective for the linear\n",
        "model, alleviating the issue of learning from imbalanced classes**. However,\n",
        "the :class:`~sklearn.ensemble.RandomForestClassifier` is still biased toward\n",
        "the majority class, mainly due to the criterion which is not suited enough to\n",
        "fight the class imbalance.\n",
        "\n",
        "对linear model的影响效果更大，对random forest model的影响反而较小。\n",
        "\n",
        "\n",
        "### Resample the training set during learning\n",
        "\n",
        "Another way is to resample the training set by **single** under-sampling or\n",
        "over-sampling some of the samples. `imbalanced-learn` provides some samplers\n",
        "to do such processing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU33RKPYmaxP"
      },
      "source": [
        "from imblearn.pipeline import make_pipeline as make_pipeline_with_sampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "lr_clf = make_pipeline_with_sampler(\n",
        "    preprocessor_linear,\n",
        "    RandomUnderSampler(random_state=42),\n",
        "    LogisticRegression(max_iter=1000),\n",
        ")"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "2m0xVLNkmaxP",
        "outputId": "a85a5ba9-6dac-406e-e0de-8619aa527d30"
      },
      "source": [
        "index += [\"Under-sampling + Logistic regression\"]\n",
        "cv_result = cross_validate(lr_clf, df_res, y_res, scoring=scoring)\n",
        "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
        "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
        "\n",
        "df_scores = pd.DataFrame(scores, index=index)\n",
        "df_scores"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Dummy classifier</th>\n",
              "      <td>0.967755</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic regression</th>\n",
              "      <td>0.970724</td>\n",
              "      <td>0.569460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest</th>\n",
              "      <td>0.971505</td>\n",
              "      <td>0.629606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic regression with balanced class weights</th>\n",
              "      <td>0.797724</td>\n",
              "      <td>0.814664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest with balanced class weights</th>\n",
              "      <td>0.963196</td>\n",
              "      <td>0.624159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Under-sampling + Logistic regression</th>\n",
              "      <td>0.789806</td>\n",
              "      <td>0.811759</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Accuracy  Balanced accuracy\n",
              "Dummy classifier                                 0.967755           0.500000\n",
              "Logistic regression                              0.970724           0.569460\n",
              "Random forest                                    0.971505           0.629606\n",
              "Logistic regression with balanced class weights  0.797724           0.814664\n",
              "Random forest with balanced class weights        0.963196           0.624159\n",
              "Under-sampling + Logistic regression             0.789806           0.811759"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia1W8OC2maxP"
      },
      "source": [
        "rf_clf = make_pipeline_with_sampler(\n",
        "    preprocessor_tree,\n",
        "    RandomUnderSampler(random_state=42),\n",
        "    RandomForestClassifier(random_state=42, n_jobs=2),\n",
        ")"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "ZPU4SA1KmaxP",
        "outputId": "8d8d35a1-df2e-48bf-f293-d5b3ec8ae4d4"
      },
      "source": [
        "index += [\"Under-sampling + Random forest\"]\n",
        "cv_result = cross_validate(rf_clf, df_res, y_res, scoring=scoring)\n",
        "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
        "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
        "\n",
        "df_scores = pd.DataFrame(scores, index=index)\n",
        "df_scores"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Dummy classifier</th>\n",
              "      <td>0.967755</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic regression</th>\n",
              "      <td>0.970724</td>\n",
              "      <td>0.569460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest</th>\n",
              "      <td>0.971505</td>\n",
              "      <td>0.629606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic regression with balanced class weights</th>\n",
              "      <td>0.797724</td>\n",
              "      <td>0.814664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest with balanced class weights</th>\n",
              "      <td>0.963196</td>\n",
              "      <td>0.624159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Under-sampling + Logistic regression</th>\n",
              "      <td>0.789806</td>\n",
              "      <td>0.811759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Under-sampling + Random forest</th>\n",
              "      <td>0.789988</td>\n",
              "      <td>0.802468</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Accuracy  Balanced accuracy\n",
              "Dummy classifier                                 0.967755           0.500000\n",
              "Logistic regression                              0.970724           0.569460\n",
              "Random forest                                    0.971505           0.629606\n",
              "Logistic regression with balanced class weights  0.797724           0.814664\n",
              "Random forest with balanced class weights        0.963196           0.624159\n",
              "Under-sampling + Logistic regression             0.789806           0.811759\n",
              "Under-sampling + Random forest                   0.789988           0.802468"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEZGR3tdmaxQ"
      },
      "source": [
        "**Applying a random under-sampler before the training of the linear model or\n",
        "random forest, allows to not focus on the majority class at the cost of\n",
        "making more mistake for samples in the majority class (i.e. decreased\n",
        "accuracy)**.\n",
        "\n",
        "We could apply any type of samplers and find which sampler is working best\n",
        "on the current dataset.\n",
        "\n",
        "Instead, we will present another way by using classifiers which will apply\n",
        "sampling internally.\n",
        "\n",
        "### Use of specific balanced algorithms from imbalanced-learn\n",
        "\n",
        "We already showed that random under-sampling can be effective on decision\n",
        "tree. However, instead of under-sampling once the dataset, one could\n",
        "under-sample the original dataset before to take a bootstrap sample. This is\n",
        "the base of the :class:`imblearn.ensemble.BalancedRandomForestClassifier` and\n",
        ":class:`~imblearn.ensemble.BalancedBaggingClassifier`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0ocsN_xmaxQ"
      },
      "source": [
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "\n",
        "rf_clf = make_pipeline(\n",
        "    preprocessor_tree,\n",
        "    BalancedRandomForestClassifier(random_state=42, n_jobs=2),\n",
        ")"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Lm2efMvpmaxQ",
        "outputId": "ce619659-d1d1-49ea-deb5-358d05ad7d4d"
      },
      "source": [
        "index += [\"Balanced random forest\"]\n",
        "cv_result = cross_validate(rf_clf, df_res, y_res, scoring=scoring)\n",
        "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
        "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
        "\n",
        "df_scores = pd.DataFrame(scores, index=index)\n",
        "df_scores"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Dummy classifier</th>\n",
              "      <td>0.967755</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic regression</th>\n",
              "      <td>0.970724</td>\n",
              "      <td>0.569460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest</th>\n",
              "      <td>0.971505</td>\n",
              "      <td>0.629606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic regression with balanced class weights</th>\n",
              "      <td>0.797724</td>\n",
              "      <td>0.814664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest with balanced class weights</th>\n",
              "      <td>0.963196</td>\n",
              "      <td>0.624159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Under-sampling + Logistic regression</th>\n",
              "      <td>0.789806</td>\n",
              "      <td>0.811759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Under-sampling + Random forest</th>\n",
              "      <td>0.789988</td>\n",
              "      <td>0.802468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balanced random forest</th>\n",
              "      <td>0.785169</td>\n",
              "      <td>0.805841</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Accuracy  Balanced accuracy\n",
              "Dummy classifier                                 0.967755           0.500000\n",
              "Logistic regression                              0.970724           0.569460\n",
              "Random forest                                    0.971505           0.629606\n",
              "Logistic regression with balanced class weights  0.797724           0.814664\n",
              "Random forest with balanced class weights        0.963196           0.624159\n",
              "Under-sampling + Logistic regression             0.789806           0.811759\n",
              "Under-sampling + Random forest                   0.789988           0.802468\n",
              "Balanced random forest                           0.785169           0.805841"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXCiquJBmaxR"
      },
      "source": [
        "The performance with the\n",
        ":class:`~imblearn.ensemble.BalancedRandomForestClassifier` is better than\n",
        "applying a single random under-sampling. We will use a gradient-boosting\n",
        "classifier within a :class:`~imblearn.ensemble.BalancedBaggingClassifier`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "po-NECofmaxR",
        "outputId": "6cee364e-97fb-462d-ded8-7a1da8fcb0d1"
      },
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "\n",
        "bag_clf = make_pipeline(\n",
        "    preprocessor_tree,\n",
        "    BalancedBaggingClassifier(\n",
        "        base_estimator=HistGradientBoostingClassifier(random_state=42),\n",
        "        n_estimators=10,\n",
        "        random_state=42,\n",
        "        n_jobs=2,\n",
        "    ),\n",
        ")\n",
        "\n",
        "index += [\"Balanced bag of histogram gradient boosting\"]\n",
        "cv_result = cross_validate(bag_clf, df_res, y_res, scoring=scoring)\n",
        "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
        "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
        "\n",
        "df_scores = pd.DataFrame(scores, index=index)\n",
        "df_scores"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Dummy classifier</th>\n",
              "      <td>0.967755</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic regression</th>\n",
              "      <td>0.970724</td>\n",
              "      <td>0.569460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest</th>\n",
              "      <td>0.971505</td>\n",
              "      <td>0.629606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic regression with balanced class weights</th>\n",
              "      <td>0.797724</td>\n",
              "      <td>0.814664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random forest with balanced class weights</th>\n",
              "      <td>0.963196</td>\n",
              "      <td>0.624159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Under-sampling + Logistic regression</th>\n",
              "      <td>0.789806</td>\n",
              "      <td>0.811759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Under-sampling + Random forest</th>\n",
              "      <td>0.789988</td>\n",
              "      <td>0.802468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balanced random forest</th>\n",
              "      <td>0.785169</td>\n",
              "      <td>0.805841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balanced bag of histogram gradient boosting</th>\n",
              "      <td>0.832600</td>\n",
              "      <td>0.814725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Accuracy  Balanced accuracy\n",
              "Dummy classifier                                 0.967755           0.500000\n",
              "Logistic regression                              0.970724           0.569460\n",
              "Random forest                                    0.971505           0.629606\n",
              "Logistic regression with balanced class weights  0.797724           0.814664\n",
              "Random forest with balanced class weights        0.963196           0.624159\n",
              "Under-sampling + Logistic regression             0.789806           0.811759\n",
              "Under-sampling + Random forest                   0.789988           0.802468\n",
              "Balanced random forest                           0.785169           0.805841\n",
              "Balanced bag of histogram gradient boosting      0.832600           0.814725"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0203ltbmaxR"
      },
      "source": [
        "This last approach is the most effective. The different under-sampling allows\n",
        "to bring some diversity for the different GBDT to learn and not focus on a\n",
        "portion of the majority class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N3BtdirnHup"
      },
      "source": [
        ""
      ],
      "execution_count": 71,
      "outputs": []
    }
  ]
}